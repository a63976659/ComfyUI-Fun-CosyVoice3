import torch
import os
import tempfile
import torchaudio
import numpy as np
import random
from .utils_cosyvoice import load_cosyvoice_model, unload_cosyvoice_model

# è¯­è¨€åˆ—è¡¨
LANGUAGES_LIST = ["ä¸æŒ‡å®š", "ä¸­æ–‡", "è‹±è¯­", "æ—¥è¯­", "éŸ©è¯­", "å¾·è¯­", "è¥¿ç­ç‰™è¯­", "æ³•è¯­", "æ„å¤§åˆ©è¯­", "ä¿„è¯­"]

# æ–¹è¨€åˆ—è¡¨
DIALECTS_LIST = ["æ— ", "å¹¿ä¸œè¯", "é—½å—è¯", "å››å·è¯", "ä¸œåŒ—è¯", "æ²³å—è¯", "é™•è¥¿è¯", "å±±è¥¿è¯", "ä¸Šæµ·è¯", "å¤©æ´¥è¯", "å±±ä¸œè¯", "å®å¤è¯", "ç”˜è‚ƒè¯"]

class Fun_CosyVoice3_Node:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                # æ ¸å¿ƒè¾“å…¥
                "å‚è€ƒéŸ³é¢‘": ("AUDIO", ),
                "æ–‡æœ¬å†…å®¹": ("STRING", {"multiline": True, "default": "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ CosyVoice 3.0 è¯­éŸ³åˆæˆç³»ç»Ÿã€‚"}),
                
                # æ¨¡å¼é€‰æ‹©
                "æ¨¡å¼": (["é›¶æ ·æœ¬å¤åˆ» (Zero-shot)", "æŒ‡ä»¤æ§åˆ¶ (Instruct)", "è·¨è¯­è¨€/ç²¾ç»†æ§åˆ¶ (Cross-lingual)"], {"default": "é›¶æ ·æœ¬å¤åˆ» (Zero-shot)"}),
                "å‚è€ƒéŸ³é¢‘æ–‡æœ¬": ("STRING", {"multiline": False, "default": "", "placeholder": "ã€é›¶æ ·æœ¬æ¨¡å¼å¿…å¡«ã€‘è¾“å…¥å‚è€ƒéŸ³é¢‘é‡Œè¯´çš„è¯"}),
                
                # --- ç»†åˆ†æ§åˆ¶ç»„ä»¶ ---
                "è¯­è¨€": (LANGUAGES_LIST, {"default": "ä¸­æ–‡"}),
                "æ–¹è¨€": (DIALECTS_LIST, {"default": "æ— "}),
                "æƒ…æ„Ÿ": ("STRING", {"multiline": False, "default": "", "placeholder": "ä¾‹å¦‚ï¼šæ‚²ä¼¤ã€æ¿€åŠ¨"}),
                "è¯­é€Ÿ": ("FLOAT", {"default": 0, "min": -30, "max": 30, "step": 0.5, "display": "slider"}),
                "éŸ³é‡": ("FLOAT", {"default": 0, "min": -30, "max": 30, "step": 0.5, "display": "slider"}),
                
                # ç³»ç»Ÿè®¾å®š
                "ç³»ç»Ÿæç¤ºè¯": ("STRING", {"multiline": False, "default": "You are a helpful assistant.", "label": "ç³»ç»Ÿè®¾å®š"}),
                "éšæœºç§å­": ("INT", {"default": 0, "min": 0, "max": 0xffffffff}),
                
                # ä¸‹è½½è®¾ç½®
                "ä¸‹è½½æº": (["ModelScope", "HuggingFace", "HF Mirror"], {"default": "ModelScope"}),
                "è‡ªåŠ¨ä¸‹è½½æ¨¡å‹": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("AUDIO",)
    RETURN_NAMES = ("éŸ³é¢‘è¾“å‡º",)
    FUNCTION = "generate_audio"
    CATEGORY = "ğŸ’¬ AIäººå·¥æ™ºèƒ½"
    DESCRIPTION = (
        "ã€Fun-CosyVoice 3.0ã€‘\n"
        "âš ï¸ å®˜æ–¹å»ºè®®ï¼šå•å¥æ–‡æœ¬ä¸è¦è¶…è¿‡ 30ç§’ï¼Œå¦åˆ™éŸ³è´¨å’ŒèŠ‚å¥ä¼šä¸‹é™ã€‚\n"
        "1. é›¶æ ·æœ¬å¤åˆ»ï¼šå¿…é¡»å¡«å†™'å‚è€ƒéŸ³é¢‘æ–‡æœ¬'ã€‚ä¼šè‡ªåŠ¨åŠ ä¸Šè¯­è¨€/æƒ…æ„Ÿç­‰æŒ‡ä»¤ã€‚\n"
        "2. æŒ‡ä»¤æ§åˆ¶ï¼šä¸»è¦ä¾èµ–è¯­è¨€ã€æ–¹è¨€ã€æƒ…æ„Ÿç­‰å‚æ•°æ§åˆ¶ã€‚\n"
        "3. æœºåˆ¶è¯´æ˜ï¼šä¸ºé˜²æ­¢æ¨¡å‹å¿µå‡ºæç¤ºè¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ„å»ºæ ‡å‡†çš„ <|endofprompt|> æ ¼å¼ã€‚"
    )

    def _save_temp_wav(self, audio_input):
        """ä¿å­˜ä¸´æ—¶ WAV ç”¨äº CosyVoice è¾“å…¥"""
        waveform = audio_input['waveform'] 
        sample_rate = audio_input['sample_rate']
        
        if waveform.dim() == 3:
            wav_tensor = waveform[0]
        else:
            wav_tensor = waveform

        if wav_tensor.shape[0] > wav_tensor.shape[1]: 
             wav_tensor = wav_tensor.t()

        # å¿…é¡»é‡é‡‡æ ·åˆ° 16k
        if sample_rate != 16000:
            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
            wav_tensor = resampler(wav_tensor)
            sample_rate = 16000

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        temp_file.close()
        torchaudio.save(temp_file.name, wav_tensor.cpu(), sample_rate)
        return temp_file.name

    def _construct_instruction(self, è¯­è¨€, æ–¹è¨€, æƒ…æ„Ÿ, è¯­é€Ÿ, éŸ³é‡):
        """å°†ç¦»æ•£å‚æ•°ç»„è£…æˆè‡ªç„¶è¯­è¨€æŒ‡ä»¤"""
        parts = []
        
        if è¯­è¨€ not in ["ä¸æŒ‡å®š", "æ— "]:
            parts.append(f"è¯·ç”¨{è¯­è¨€}ã€‚")
            
        if æ–¹è¨€ not in ["ä¸æŒ‡å®š", "æ— "]:
            parts.append(f"ä½¿ç”¨{æ–¹è¨€}ã€‚")
            
        if æƒ…æ„Ÿ.strip():
            parts.append(f"ä½¿ç”¨{æƒ…æ„Ÿ.strip()}çš„è¯­æ°”ã€‚")
        
        if è¯­é€Ÿ != 0:
            speed_str = "åŠ å¿«" if è¯­é€Ÿ > 0 else "æ”¾æ…¢"
            parts.append(f"è¯­é€Ÿ{speed_str}{abs(è¯­é€Ÿ)}ã€‚")
            
        if éŸ³é‡ != 0:
            vol_str = "è°ƒå¤§" if éŸ³é‡ > 0 else "è°ƒå°"
            parts.append(f"éŸ³é‡{vol_str}{abs(éŸ³é‡)}ã€‚")
            
        return "".join(parts)

    def _construct_final_prompt(self, sys_prompt, instruct_str, ref_text=""):
        """
        ä¸¥æ ¼æŒ‰ç…§å®˜æ–¹æ ¼å¼æ„å»º Prompt: 
        System + Instruct + <|endofprompt|> + Reference Text (å¯é€‰)
        """
        # å®˜æ–¹å¼ºè°ƒå¿…é¡»æœ‰ instructï¼Œå¦‚æœç”¨æˆ·æ²¡å¡«ä»»ä½•æ§åˆ¶å‚æ•°ï¼Œæˆ‘ä»¬ç»™ä¸€ä¸ªé»˜è®¤çš„æ— å®³æŒ‡ä»¤
        # é˜²æ­¢æ¨¡å‹å› ä¸ºç¼ºå°‘ instruct è€ŒæŠŠ system prompt å½“æˆæ–‡æœ¬å¿µå‡ºæ¥
        final_instruct = instruct_str
        if not final_instruct.strip():
            final_instruct = "è¯·ä½¿ç”¨è¯¥å£°éŸ³åˆæˆã€‚" 

        # æ‹¼æ¥ System å’Œ Instruct
        # æ³¨æ„ï¼šä¸è¦è‡ªå·±ä¹±åŠ æ¢è¡Œç¬¦ï¼Œé™¤éç¡®å®šæ¨¡å‹éœ€è¦ã€‚CosyVoiceé€šå¸¸æ˜¯ç´§å‡‘æ‹¼æ¥ã€‚
        header = f"{sys_prompt} {final_instruct}".strip()
        
        # åŠ ä¸Šæ ¸å¿ƒåˆ†éš”ç¬¦
        full_prompt = f"{header}<|endofprompt|>"
        
        # å¦‚æœæœ‰å‚è€ƒæ–‡æœ¬ï¼ˆZero-shotæ¨¡å¼ï¼‰ï¼Œè¿½åŠ åœ¨åé¢
        if ref_text.strip():
            full_prompt += ref_text.strip()
            
        return full_prompt

    def generate_audio(self, å‚è€ƒéŸ³é¢‘, æ–‡æœ¬å†…å®¹, æ¨¡å¼, å‚è€ƒéŸ³é¢‘æ–‡æœ¬, è¯­è¨€, æ–¹è¨€, æƒ…æ„Ÿ, è¯­é€Ÿ, éŸ³é‡, ç³»ç»Ÿæç¤ºè¯, éšæœºç§å­, ä¸‹è½½æº, è‡ªåŠ¨ä¸‹è½½æ¨¡å‹):
        
        # é•¿åº¦è­¦å‘Š
        if len(æ–‡æœ¬å†…å®¹) > 100: # ä¼°ç®—å€¼ï¼Œä¸­æ–‡100å­—å¤§æ¦‚30ç§’å·¦å³
            print("[Warning] å¾…åˆæˆæ–‡æœ¬è¾ƒé•¿ï¼ŒCosyVoice3 å»ºè®®å•å¥ä¸è¶…è¿‡ 30ç§’ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´å¤è¯»æˆ–éŸ³è´¨ä¸‹é™ã€‚")

        # è®¾ç½®éšæœºç§å­
        if éšæœºç§å­ is not None:
            torch.manual_seed(éšæœºç§å­)
            if torch.cuda.is_available():
                torch.cuda.manual_seed_all(éšæœºç§å­)
        
        temp_wav_path = None
        model_name = "Fun-CosyVoice3-0.5B-2512"

        try:
            # 1. å‡†å¤‡å‚è€ƒéŸ³é¢‘
            temp_wav_path = self._save_temp_wav(å‚è€ƒéŸ³é¢‘)
            
            # 2. åŠ è½½æ¨¡å‹
            model = load_cosyvoice_model(model_name, self.device, auto_download=è‡ªåŠ¨ä¸‹è½½æ¨¡å‹, source=ä¸‹è½½æº)
            
            print(f"[CosyVoice3] Generating... Mode: {æ¨¡å¼}")
            
            # 3. æ„å»ºæŒ‡ä»¤éƒ¨åˆ†
            instruct_str = self._construct_instruction(è¯­è¨€, æ–¹è¨€, æƒ…æ„Ÿ, è¯­é€Ÿ, éŸ³é‡)
            if instruct_str:
                print(f"[CosyVoice3] Instruct: {instruct_str}")

            generator = None
            
            # 4. æ ¹æ®æ¨¡å¼æ‰§è¡Œæ¨ç†
            if æ¨¡å¼ == "é›¶æ ·æœ¬å¤åˆ» (Zero-shot)":
                if not å‚è€ƒéŸ³é¢‘æ–‡æœ¬.strip():
                    raise ValueError("ã€é›¶æ ·æœ¬æ¨¡å¼ã€‘å¿…é¡»å¡«å†™'å‚è€ƒéŸ³é¢‘æ–‡æœ¬'ï¼")
                
                # æ„å»ºå®Œæ•´çš„ Prompt (åŒ…å« System, Instruct, Separator, RefText)
                final_prompt = self._construct_final_prompt(ç³»ç»Ÿæç¤ºè¯, instruct_str, å‚è€ƒéŸ³é¢‘æ–‡æœ¬)
                print(f"[Debug] Final Prompt: {final_prompt}")

                generator = model.inference_zero_shot(
                    tts_text=æ–‡æœ¬å†…å®¹,
                    prompt_text=final_prompt,
                    prompt_speech_16k=temp_wav_path,
                    stream=False
                )

            elif æ¨¡å¼ == "æŒ‡ä»¤æ§åˆ¶ (Instruct)":
                # Instruct æ¨¡å¼æ²¡æœ‰ RefTextï¼Œä½†åŒæ ·å¿…é¡»æœ‰ <|endofprompt|>
                final_prompt = self._construct_final_prompt(ç³»ç»Ÿæç¤ºè¯, instruct_str, ref_text="")
                print(f"[Debug] Final Prompt: {final_prompt}")

                generator = model.inference_instruct2(
                    tts_text=æ–‡æœ¬å†…å®¹,
                    prompt_text=final_prompt,
                    prompt_speech_16k=temp_wav_path,
                    stream=False
                )

            elif æ¨¡å¼ == "è·¨è¯­è¨€/ç²¾ç»†æ§åˆ¶ (Cross-lingual)":
                # Cross-lingual å®˜æ–¹æ¥å£å¯èƒ½ä¸ä½¿ç”¨ text promptï¼Œæˆ–è€…åªä½¿ç”¨åŸºç¡€ prompt
                # ä½†ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬è¿˜æ˜¯æ„å»ºä¸€ä¸ªåŸºç¡€çš„ prompt å¯¹è±¡
                # æ³¨æ„ï¼šinference_cross_lingual çš„å‚æ•°å®šä¹‰å¯èƒ½ä¸åŒ…å« prompt_textï¼Œè§†å…·ä½“ç‰ˆæœ¬è€Œå®š
                # è¿™é‡Œæˆ‘ä»¬å‡è®¾å®ƒä¸»è¦ä¾èµ–éŸ³é¢‘ç‰¹å¾ã€‚å¦‚æœæ”¯æŒ prompt_textï¼Œé€»è¾‘åŒä¸Šã€‚
                
                generator = model.inference_cross_lingual(
                    tts_text=æ–‡æœ¬å†…å®¹,
                    prompt_speech_16k=temp_wav_path,
                    stream=False
                )

            # 5. è·å–ç»“æœ
            final_output = None
            for i, result in enumerate(generator):
                final_output = result
            
            if final_output is None:
                raise Exception("ç”Ÿæˆå¤±è´¥ï¼Œæ¨¡å‹æœªè¿”å›éŸ³é¢‘æ•°æ®ã€‚")

            out_wav = final_output['tts_speech'] 
            target_sr = model.sample_rate 
            
            if out_wav.dim() == 1:
                out_wav = out_wav.unsqueeze(0).unsqueeze(0)
            elif out_wav.dim() == 2:
                out_wav = out_wav.unsqueeze(0)

            return ({"waveform": out_wav.cpu(), "sample_rate": target_sr},)

        except Exception as e:
            import traceback
            traceback.print_exc()
            raise Exception(f"CosyVoice Error: {str(e)}")
        
        finally:
            if temp_wav_path and os.path.exists(temp_wav_path):
                os.remove(temp_wav_path)
            unload_cosyvoice_model()